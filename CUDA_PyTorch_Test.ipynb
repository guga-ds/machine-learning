{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guga-ds/machine-learning/blob/master/CUDA_PyTorch_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCMW1mMvypyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def describe(x):\n",
        "  print(\"Type {}\".format(x.type()))\n",
        "  print(\"Size {}\".format(x.shape))\n",
        "  print(\"Value {}\".format(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGWJsqCiE6S8",
        "colab_type": "code",
        "outputId": "8604570f-04e7-4130-bfc0-6cc78140077e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xpZfuzEEu-7",
        "colab_type": "code",
        "outputId": "7d86c67c-7dee-44a0-c7b6-72119c1a0140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXTQmUbKx8kQ",
        "colab_type": "code",
        "outputId": "97c8ada6-aa7e-4170-c93d-8babbab38ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqYAjBnGyA0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8708f0f2-ce2c-481e-99af-3bf19ac0c1a4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZLazpIgyQ02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "994a0c57-3f20-406f-cf1a-4edf7330c53f"
      },
      "source": [
        "x = torch.rand(3,3).to(device)\n",
        "describe(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type torch.cuda.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.7945, 0.7195, 0.9007],\n",
            "        [0.7340, 0.9208, 0.8494],\n",
            "        [0.1808, 0.5068, 0.4090]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEG2FoDeymQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "e8a81261-c16c-4e4f-bfad-d4e9842819d6"
      },
      "source": [
        "y = torch.rand(3,3)\n",
        "x + y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ac838f838182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: expected backend CUDA and dtype Float but got backend CPU and dtype Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WIhZmfg9hZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e4b72bb7-ae27-4f55-cac5-95e8274b91aa"
      },
      "source": [
        "describe(y)\n",
        "# we need to use the same device for realize any operations without\n",
        "# that send an error."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type torch.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.6715, 0.7661, 0.6738],\n",
            "        [0.7073, 0.1226, 0.7896],\n",
            "        [0.4101, 0.7865, 0.5491]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pnh9uZQ9l9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ed8b9d04-615d-4c52-a736-a349957f046c"
      },
      "source": [
        "cpu_device= torch.device(\"cpu\")\n",
        "y = y.to(cpu_device)\n",
        "x = x.to(cpu_device)\n",
        "x + y\n",
        "describe(x)\n",
        "describe(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type torch.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.7945, 0.7195, 0.9007],\n",
            "        [0.7340, 0.9208, 0.8494],\n",
            "        [0.1808, 0.5068, 0.4090]])\n",
            "Type torch.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.6715, 0.7661, 0.6738],\n",
            "        [0.7073, 0.1226, 0.7896],\n",
            "        [0.4101, 0.7865, 0.5491]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKSORaF95Xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "af9d0d19-d9bc-438a-b99c-3f9ecce773ee"
      },
      "source": [
        "y = y.to(device)\n",
        "x = x.to(device)\n",
        "x + y\n",
        "describe(x)\n",
        "describe(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type torch.cuda.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.7945, 0.7195, 0.9007],\n",
            "        [0.7340, 0.9208, 0.8494],\n",
            "        [0.1808, 0.5068, 0.4090]], device='cuda:0')\n",
            "Type torch.cuda.FloatTensor\n",
            "Size torch.Size([3, 3])\n",
            "Value tensor([[0.6715, 0.7661, 0.6738],\n",
            "        [0.7073, 0.1226, 0.7896],\n",
            "        [0.4101, 0.7865, 0.5491]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbekArK6_asH",
        "colab_type": "text"
      },
      "source": [
        "*italicized text*\n",
        "Keemp in mind that its is expensive to move data back and forth from the GPU. Therefore, the typical procedure involves doing many of the parallelizable computations on the GPU and then transferring just the final result back to the CPU. The best practice is use CUDA_VISIBLE_DEVICES i.e. multiple GPUs\n",
        "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZHcUFpVAF-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}